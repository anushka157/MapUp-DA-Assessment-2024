# -*- coding: utf-8 -*-
"""Python_Task_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n0o9y9Y4WAigFW1PJIc4lf6RZKC1liRI

Question 1: Reverse List by N Elements
Problem Statement:

Write a function that takes a list and an integer n, and returns the list with every group of n elements reversed. If there are fewer than n elements left at the end, reverse all of them.

Requirements:

You must not use any built-in slicing or reverse functions to directly reverse the sublists.
The result should reverse the elements in groups of size n.
"""

from typing import List
import pandas as pd

def reverse_by_n_elements(lst: List[int], n: int) -> List[int]:
    """
    Reverses the input list by groups of n elements.

    Parameters:
    lst (List[int]): The list of integers to reverse.
    n (int): The group size for reversing the list elements.

    Returns:
    List[int]: A list where elements are reversed in groups of size n.
    """
    result = []
    for i in range(0, len(lst), n):
        temp = []
        for j in range(i, min(i + n, len(lst))):
            temp.append(lst[j])
        for k in range(len(temp) - 1, -1, -1):
            result.append(temp[k])
    return result

def main() -> None:
    """
    Takes user input, processes it, and prints the reversed list by n elements.
    """
    user_input = input("Enter a list of elements separated by spaces: ")
    lst = list(map(int, user_input.split()))

    n = int(input("Enter the value of n: "))

    output = reverse_by_n_elements(lst, n)
    print("Output:", output)

if __name__ == "__main__":
    main()

"""Question 2: Lists & Dictionaries
Problem Statement:

Write a function that takes a list of strings and groups them by their length. The result should be a dictionary where:

The keys are the string lengths.
The values are lists of strings that have the same length as the key.
Requirements:

Each string should appear in the list corresponding to its length.
The result should be sorted by the lengths (keys) in ascending order.
"""

from typing import Dict, List
import pandas as pd

def group_by_length(lst: List[str]) -> Dict[int, List[str]]:
    """
    Groups the strings by their length and returns a dictionary.

    Parameters:
    lst (List[str]): List of strings to be grouped by their lengths.

    Returns:
    Dict[int, List[str]]: A dictionary where the keys are string lengths and
    the values are lists of strings of that length.
    """
    length_dict: Dict[int, List[str]] = {}

    for string in lst:
        length = len(string)
        if length not in length_dict:
            length_dict[length] = []
        length_dict[length].append(string)

    return dict(sorted(length_dict.items()))

def main() -> None:
    """
    Takes user input, processes it, and prints the grouped strings by length.
    """
    user_input = input("Enter strings separated by commas: ")
    strings = [s.strip() for s in user_input.split(',')]

    output = group_by_length(strings)
    print("Output:", output)

if __name__ == "__main__":
    main()

"""Question 3: Flatten a Nested Dictionary
You are given a nested dictionary that contains various details (including lists and sub-dictionaries). Your task is to write a Python function that flattens the dictionary such that:

Nested keys are concatenated into a single key with levels separated by a dot (.).
List elements should be referenced by their index, enclosed in square brackets (e.g., sections[0]).
For example, if a key points to a list, the index of the list element should be appended to the key string, followed by a dot to handle further nested dictionaries.

Requirements:

Nested Dictionary: Flatten nested dictionaries into a single level, concatenating keys.
Handling Lists: Flatten lists by using the index as part of the key.
Key Separator: Use a dot (.) as a separator between nested key levels.
Empty Input: The function should handle empty dictionaries gracefully.
Nested Depth: You can assume the dictionary has a maximum of 4 levels of nesting.
"""

from typing import Dict
import pandas as pd

def flatten_dict(nested_dict: Dict, sep: str = '.') -> Dict:
    """
    Flattens a nested dictionary into a single-level dictionary with dot notation for keys.

    Parameters:
    nested_dict (Dict): The nested dictionary to be flattened.
    sep (str): The separator used between parent and child keys (default is '.').

    Returns:
    Dict: A flattened dictionary where nested keys are concatenated with the separator.
    """
    def _flatten(current_dict: Dict, parent_key: str = '') -> Dict:
        items: Dict = {}
        for key, value in current_dict.items():
            new_key = f"{parent_key}{sep}{key}" if parent_key else key
            if isinstance(value, dict):
                items.update(_flatten(value, new_key))
            elif isinstance(value, list):
                for i, item in enumerate(value):
                    if isinstance(item, dict):
                        items.update(_flatten(item, f"{new_key}[{i}]"))
                    else:
                        items[f"{new_key}[{i}]"] = item
            else:
                items[new_key] = value
        return items

    return _flatten(nested_dict)

nested_dict = {
    "road": {
        "name": "Highway 1",
        "length": 350,
        "sections": [
            {
                "id": 1,
                "condition": {
                    "pavement": "good",
                    "traffic": "moderate"
                }
            }
        ]
    }
}

flattened_dict = flatten_dict(nested_dict)
print(flattened_dict)

"""Question 4: Generate Unique Permutations
Problem Statement:

You are given a list of integers that may contain duplicates. Your task is to generate all unique permutations of the list. The output should not contain any duplicate permutations.
"""

from itertools import permutations
from typing import List
import pandas as pd

def unique_permutations(nums: List[int]) -> List[List[int]]:
    """
    Generates unique permutations of the input list.

    Parameters:
    nums (List[int]): List of integers.

    Returns:
    List[List[int]]: List of unique permutations.
    """
    unique_perms = set(permutations(nums))

    return sorted([list(perm) for perm in unique_perms])

def main() -> None:
    """
    Takes user input, generates unique permutations, and prints them in the desired format.
    """
    user_input = input("Enter integers separated by commas: ")

    nums = [int(num.strip()) for num in user_input.split(',')]

    output = unique_permutations(nums)

    print("Output:")
    print("[")
    for perm in output:
        print(f"    {perm},")
    print("]")

if __name__ == "__main__":
    main()

"""Question 5: Find All Dates in a Text
Problem Statement:

You are given a string that contains dates in various formats (such as "dd-mm-yyyy", "mm/dd/yyyy", "yyyy.mm.dd", etc.). Your task is to identify and return all the valid dates present in the string.

You need to write a function find_all_dates that takes a string as input and returns a list of valid dates found in the text. The dates can be in any of the following formats:

dd-mm-yyyy
mm/dd/yyyy
yyyy.mm.dd
You are required to use regular expressions to identify these dates.
"""

from typing import List
import re
import pandas as pd

def find_all_dates(text: str) -> List[str]:
    """
    This function takes a string as input and returns a list of valid dates
    in 'dd-mm-yyyy', 'mm/dd/yyyy', or 'yyyy.mm.dd' format found in the string.

    Parameters:
    text (str): A string containing the dates in various formats.

    Returns:
    List[str]: A list of valid dates in the formats specified.
    """
    date_patterns = [
        r'\b\d{2}-\d{2}-\d{4}\b', 
        r'\b\d{2}/\d{2}/\d{4}\b',  
        r'\b\d{4}\.\d{2}\.\d{2}\b' 
    ]

    combined_pattern = '|'.join(date_patterns)

    found_dates = re.findall(combined_pattern, text)

    return found_dates

def main() -> None:
    """
    Takes user input, processes the text, and prints all valid dates found in the text.
    """
    user_input = input("Enter text containing dates: ")

    output = find_all_dates(user_input)

    print("Output:")
    print(output)

if __name__ == "__main__":
    main()

"""Question 6: Decode Polyline, Convert to DataFrame with Distances
You are given a polyline string, which encodes a series of latitude and longitude coordinates. Polyline encoding is a method to efficiently store latitude and longitude data using fewer bytes. The Python polyline module allows you to decode this string into a list of coordinates.

Write a function that performs the following operations:

Decode the polyline string using the polyline module into a list of (latitude, longitude) coordinates.
Convert these coordinates into a Pandas DataFrame with the following columns:
latitude: Latitude of the coordinate.
longitude: Longitude of the coordinate.
distance: The distance (in meters) between the current row's coordinate and the previous row's one. The first row will have a distance of 0 since there is no previous point.
Calculate the distance using the Haversine formula for points in successive rows.
"""

from typing import List
import polyline
import pandas as pd
import numpy as np

def haversine(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
    """Calculates the Haversine distance between two geographical points."""
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])

    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    r = 6371000  
    return c * r

def polyline_to_dataframe(polyline_str: str) -> pd.DataFrame:
    """
    Converts a polyline string into a DataFrame with latitude, longitude, and distance between consecutive points.

    Args:
        polyline_str (str): The encoded polyline string.

    Returns:
        pd.DataFrame: A DataFrame containing latitude, longitude, and distance in meters.
    """
    coordinates: List[tuple] = polyline.decode(polyline_str)

    df = pd.DataFrame(coordinates, columns=['latitude', 'longitude'])

    distances = [0.0]  
    for i in range(1, len(coordinates)):
        dist = haversine(
            df.latitude[i-1], df.longitude[i-1],
            df.latitude[i], df.longitude[i]
        )
        distances.append(dist)

    df['distance'] = distances
    return df

polyline_str = "u{w`F~g|z@d@f@cGmBmAhD"
df_coordinates = polyline_to_dataframe(polyline_str)
print(df_coordinates)

"""Question 7: Matrix Rotation and Transformation
Write a function that performs the following operations on a square matrix (n x n):

Rotate the matrix by 90 degrees clockwise.
After rotation, for each element in the rotated matrix, replace it with the sum of all elements in the same row and column (in the rotated matrix), excluding itself.
The function should return the transformed matrix.
"""

from typing import List
import pandas as pd

def rotate_and_transform_matrix(matrix: List[List[int]]) -> List[List[int]]:
    """
    Rotates a square matrix by 90 degrees clockwise and transforms it.

    Args:
        matrix (List[List[int]]): A square matrix to be rotated and transformed.

    Returns:
        List[List[int]]: The transformed matrix after rotation.
    """
    n = len(matrix)

    rotated_matrix = [[matrix[n - j - 1][i] for j in range(n)] for i in range(n)]

    final_matrix = [[0] * n for _ in range(n)]

    for i in range(n):
        for j in range(n):
            row_sum = sum(rotated_matrix[i]) - rotated_matrix[i][j]
            col_sum = sum(rotated_matrix[k][j] for k in range(n)) - rotated_matrix[i][j]
            final_matrix[i][j] = row_sum + col_sum

    return final_matrix

def main() -> None:
    """
    Main function to execute the matrix rotation and transformation.
    """
    n = int(input("Enter the size of the matrix (n x n): "))

    matrix: List[List[int]] = []
    print(f"Enter the elements of the {n} x {n} matrix row by row (space-separated):")
    for i in range(n):
        row = list(map(int, input(f"Row {i + 1}: ").split()))
        if len(row) != n:
            print(f"Please enter exactly {n} elements.")
            return
        matrix.append(row)

    result = rotate_and_transform_matrix(matrix)

    print("The transformed matrix is:")
    for row in result:
        print(row)

if __name__ == "__main__":
    main()

"""Question 8: Time Check
You are given a dataset, dataset-1.csv, containing columns id, id_2, and timestamp (startDay, startTime, endDay, endTime). The goal is to verify the completeness of the time data by checking whether the timestamps for each unique (id, id_2) pair cover a full 24-hour period (from 12:00:00 AM to 11:59:59 PM) and span all 7 days of the week (from Monday to Sunday).

Create a function that accepts dataset-1.csv as a DataFrame and returns a boolean series that indicates if each (id, id_2) pair has incorrect timestamps. The boolean series must have multi-index (id, id_2).
"""

import pandas as pd
from datetime import datetime, timedelta

import os
check_colab=False
if 'COLAB_GPU' in os.environ:
    from google.colab import files
    check_colab=True
    print("Running on Google Colab")
else:
    print("Running on local machine")

def load_dataset(file_path: str) -> pd.DataFrame:
    """Load a dataset from a CSV file."""
    df = pd.read_csv(file_path)
    return df

def get_date_from_day(base_date: datetime, day_name: str) -> datetime:
    """Get the date corresponding to a specific day name based on the base date."""
    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']

    day_index = days_of_week.index(day_name)
    days_ahead = (day_index - base_date.weekday()) % 7  
    return (base_date + timedelta(days=days_ahead)).replace(hour=0, minute=0, second=0, microsecond=0)

def time_check(df: pd.DataFrame) -> pd.Series:
    """Verify the completeness of the data by checking whether the timestamps for each unique (`id`, `id_2`) pair cover a full 24-hour and 7 days period."""
    required_columns = ['startDay', 'startTime', 'endDay', 'endTime']
    if not all(col in df.columns for col in required_columns):
        raise ValueError("Dataset must contain 'startDay', 'startTime', 'endDay', and 'endTime' columns.")

    print("First few rows of the dataset:")
    print(df.head())

    base_date = datetime.now()

    df['start_datetime'] = df.apply(lambda row: get_date_from_day(base_date, row['startDay']) + pd.to_timedelta(row['startTime']), axis=1)
    df['end_datetime'] = df.apply(lambda row: get_date_from_day(base_date, row['endDay']) + pd.to_timedelta(row['endTime']), axis=1)

    completeness_status = []

    for (id_val, id2_val), group in df.groupby(['id', 'id_2']):
        covered_days = set(group['startDay'].unique()) | set(group['endDay'].unique())

        all_days_covered = all(day in covered_days for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])

        time_coverage_complete = True
        for date in pd.date_range(start=group['start_datetime'].min().date(), end=group['end_datetime'].max().date()):
            day_data = group[(group['start_datetime'].dt.date == date.date()) | (group['end_datetime'].dt.date == date.date())]

            if not day_data['start_datetime'].dt.hour.isin(range(24)).all() or not day_data['end_datetime'].dt.hour.isin(range(24)).all():
                time_coverage_complete = False
                break

        completeness_status.append((id_val, id2_val, all_days_covered and time_coverage_complete))

    result = pd.DataFrame(completeness_status, columns=['id', 'id_2', 'is_complete'])
    result.set_index(['id', 'id_2'], inplace=True)

    return result['is_complete']


def main() -> None:
    """Main function to execute the time checking process."""

    if check_colab==True:
        uploaded = files.upload()

        for filename in uploaded.keys():
            file_path = filename  
            df = load_dataset(file_path)
    else:
        print('Wanted to use default dataset? \n (Y) Yes \t (N) No')
        user_choice = input()
        if user_choice.lower() == 'y':
            df = load_dataset(os.path.abspath('datasets/dataset-1.csv'))
        else:
            file_path = input('Enter file path: ')
            df = load_dataset(file_path)
    try:
        completeness_result = time_check(df)
        print(completeness_result)
    except ValueError as e:
        print(e)

if __name__ == "__main__":
    main()
